{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3ef9160a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8448    0.8810    0.8625      4975\n",
      "    positive     0.8770    0.8398    0.8580      5025\n",
      "\n",
      "    accuracy                         0.8603     10000\n",
      "   macro avg     0.8609    0.8604    0.8603     10000\n",
      "weighted avg     0.8610    0.8603    0.8603     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8977    0.8907    0.8942      4975\n",
      "    positive     0.8926    0.8995    0.8960      5025\n",
      "\n",
      "    accuracy                         0.8951     10000\n",
      "   macro avg     0.8951    0.8951    0.8951     10000\n",
      "weighted avg     0.8951    0.8951    0.8951     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8963    0.8808    0.8885      4975\n",
      "    positive     0.8840    0.8991    0.8915      5025\n",
      "\n",
      "    accuracy                         0.8900     10000\n",
      "   macro avg     0.8901    0.8900    0.8900     10000\n",
      "weighted avg     0.8901    0.8900    0.8900     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "data = pd.read_csv(\"../IMDB-Dataset-GoogleTranslate-Processed2.csv\")\n",
    "review, sentiment = data[\"review\"], data[\"sentiment\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    review, sentiment, test_size=0.2, random_state=0\n",
    ")\n",
    "nb_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer()),\n",
    "        (\"clf\", MultinomialNB(fit_prior=True, class_prior=None)),\n",
    "    ]\n",
    ")\n",
    "svc_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer()),\n",
    "        (\"clf\", LinearSVC(dual=\"auto\")),\n",
    "    ]\n",
    ")\n",
    "logistic_regression_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer()),\n",
    "        (\"clf\", LogisticRegression(solver=\"saga\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "nb_pipeline.fit(x_train, y_train)\n",
    "svc_pipeline.fit(x_train, y_train)\n",
    "logistic_regression_pipeline.fit(x_train, y_train)\n",
    "\n",
    "predict_1 = nb_pipeline.predict(x_test)\n",
    "predict_2 = svc_pipeline.predict(x_test)\n",
    "predict_3 = logistic_regression_pipeline.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, predict_1, digits=4))\n",
    "print(classification_report(y_test, predict_2, digits=4))\n",
    "print(classification_report(y_test, predict_3, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c5939b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(hræðilegur frábær) Positive, score is 1.122848\n",
      "(slæmur vel besta) Positive, score is 4.489404\n",
      "(lélegur vel) Negative, score is 0.106368\n"
     ]
    }
   ],
   "source": [
    "def evaluate_score(text):\n",
    "    text = [text]\n",
    "    s = logistic_regression_pipeline.predict(text)\n",
    "    # find all features and coefficients that have the text and sum up the values\n",
    "    s = sum(\n",
    "        [\n",
    "            i[1]\n",
    "            for x, i in enumerate(\n",
    "                zip(\n",
    "                    logistic_regression_pipeline[0].get_feature_names_out(),\n",
    "                    logistic_regression_pipeline[1].coef_[0],\n",
    "                )\n",
    "            )\n",
    "            if i[0] in text[0].split(\" \")\n",
    "        ]\n",
    "    )\n",
    "    if s >= 1:\n",
    "        print(\"(%s) Positive, score is %f\" % (text[0], s))\n",
    "    else:\n",
    "        print(\"(%s) Negative, score is %f\" % (text[0], s))\n",
    "\n",
    "\n",
    "evaluate_score(\"hræðilegur frábær\")\n",
    "evaluate_score(\"slæmur vel besta\")\n",
    "evaluate_score(\"lélegur vel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(solver='saga')\n",
      "\t-11.377\thræðilegur     \t\t12.4996\tfrábær         \n",
      "\t-9.104\tslæmur         \t\t7.6903\tvel            \n",
      "\t-8.970\tversta         \t\t5.9035\tbesta          \n",
      "\t-8.604\tleiðinlegur    \t\t5.7820\telska          \n",
      "\t-7.584\tlélegur        \t\t5.2837\tfrábærlega     \n",
      "\t-6.317\tilla           \t\t4.9943\tskemmtilegur   \n",
      "\t-5.365\tvonbrigði      \t\t4.8503\tfullkominn     \n",
      "\t-5.256\tpirrandi       \t\t4.7078\tdásamlegur     \n",
      "\t-5.247\tbara           \t\t4.6765\tnjóta          \n",
      "\t-5.224\tlíta           \t\t4.5580\thrífandi       \n"
     ]
    }
   ],
   "source": [
    "def get_most_important_features(vectorizer, model, n=5):\n",
    "    index_to_word = {v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "\n",
    "    # loop for each class\n",
    "    classes = {}\n",
    "    for class_index in range(model.coef_.shape[0]):\n",
    "        word_importances = [\n",
    "            (el, index_to_word[i]) for i, el in enumerate(model.coef_[class_index])\n",
    "        ]\n",
    "        sorted_coeff = sorted(word_importances, key=lambda x: x[0], reverse=True)\n",
    "        tops = sorted(sorted_coeff[:n], key=lambda x: x[0])\n",
    "        bottom = sorted_coeff[-n:]\n",
    "        classes[class_index] = {\"tops\": tops, \"bottom\": bottom}\n",
    "    return classes\n",
    "\n",
    "\n",
    "def show_most_informative_features(vectorizer, clf, n=20):\n",
    "    print(clf)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[: -(n + 1) : -1])\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print(\"\\t%.3f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))\n",
    "\n",
    "\n",
    "# show_most_informative_features(pipeline_2[0], pipeline_2[1], n=5)\n",
    "show_most_informative_features(\n",
    "    logistic_regression_pipeline[0], logistic_regression_pipeline[1], n=10\n",
    ")\n",
    "\n",
    "\n",
    "def plot_important_words(top_scores, top_words, bottom_scores, bottom_words, name):\n",
    "    top_pairs = [(a, b) for a, b in zip(top_words, top_scores)]\n",
    "    top_pairs = sorted(top_pairs, key=lambda x: x[1])\n",
    "\n",
    "    bottom_pairs = [(a, b) for a, b in zip(bottom_words, bottom_scores)]\n",
    "    bottom_pairs = sorted(bottom_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    top_words = [a[0] for a in top_pairs]\n",
    "    top_scores = [a[1] for a in top_pairs]\n",
    "\n",
    "    bottom_words = [a[0] for a in bottom_pairs]\n",
    "    bottom_scores = [a[1] for a in bottom_pairs]\n",
    "\n",
    "    print(top_words)\n",
    "    print(top_scores)\n",
    "\n",
    "    # ax = plt.subplot(121)\n",
    "    # y_pos = np.arange(len(bottom_words))\n",
    "    # p1 = plt.barh(y_pos, bottom_scores, align=\"center\")\n",
    "    # plt.yticks(y_pos, bottom_words)\n",
    "    # plt.xlabel(\"Score\")\n",
    "    # #plt.bar_label(p1, fmt='%.2f')\n",
    "\n",
    "    # plt.savefig(\"negative_lr.jpg\",bbox_inches='tight')\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.figure(figsize=(12, 8))\n",
    "    ax = plt.subplot(122)\n",
    "    y_pos = np.arange(len(top_words))\n",
    "    p2 = plt.barh(y_pos, top_scores, align=\"center\")\n",
    "    plt.yticks(y_pos, top_words)\n",
    "    plt.xlabel(\"Score\")\n",
    "    # plt.bar_label(p2, fmt='%.2f')\n",
    "    plt.savefig(\"positive_lr.jpg\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "importance = get_most_important_features(pipeline_3[0], pipeline_3[1], 10)\n",
    "top_scores = [a[0] for a in importance[0][\"tops\"]]\n",
    "top_words = [a[1] for a in importance[0][\"tops\"]]\n",
    "bottom_scores = [a[0] for a in importance[0][\"bottom\"]]\n",
    "bottom_words = [a[1] for a in importance[0][\"bottom\"]]\n",
    "\n",
    "\n",
    "plot_important_words(top_scores, top_words, bottom_scores, bottom_words, \"Sentiment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
