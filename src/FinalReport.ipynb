{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2644f3e",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Machine Translated Icelandic corpus\n",
    "\n",
    "Nemendur\n",
    "- Ólafur Aron Jóhannsson, Eysteinn Örn, Birkir Arndal\n",
    "\n",
    "Leiðbeinendur\n",
    "- Hrafn Loftsson (hrafn@ru.is)\n",
    "- Stefán Ólafsson (stefanola@ru.is)\n",
    "\n",
    "\n",
    "# Contents\n",
    "1 [Sentiment Analysis on Machine Translated Icelandic corpus](#sentiment-analysis-on-machine-translated-icelandic-corpus)\\\n",
    "2 [Contents](#contents)\\\n",
    "2.1 [Abstract](#abstract)\\\n",
    "2.2 [Introduction](#introduction)\\\n",
    "2.3 [Machine Translations](#machine-translations)\\\n",
    "2.3.1 [Google Translate](#google-translate)\\\n",
    "2.3.2 [Miðeind](#miðeind)\\\n",
    "2.4 [Pre-Processing and feature extraction](#pre-processing-feature-extraction)\\\n",
    "3 [Baseline Classifier Evaluation](#baseline-classifier-evaluation)\\\n",
    "3.1 [Support Vector Classifier](#support-vector-classifier)\\\n",
    "3.2 [Logistic Regression](#logistic-regression)\\\n",
    "3.3 [Naive Bayes](#naive-bayes)\\\n",
    "3.4 [Testing](#testing)\\\n",
    "4 [Next Steps](#next-steps)\\\n",
    "5 [Burndown Chart](#burndown-chart)\\\n",
    "6 [Risk Analysis](#risk-analysis)\n",
    "7 [Status Meetings](#status-meetings)\\\n",
    "\n",
    "\n",
    "## Abstract\n",
    "\n",
    "\n",
    "Translating English text into low-resource languages and assessing sentiment is a subject that has received extensive research attention for numerous languages, yet Icelandic remains relatively unexplored in this context. We leverage a range of baseline classifiers and deep learning models to investigate whether sentiment can be effectively conveyed across languages, even when employing machine translation services such as Google Translate and Miðeind machine translation.\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this research endeavor, we utilized an IMDB dataset comprising 50,000 reviews, each categorized as either positive or negative in sentiment, with 25.000 being positive and 25.000 being negative. Our methodology involved the translation of these reviews using both Google Translate and Miðeind Translate. Subsequently, we subjected all three datasets, including the original English version and the two translations, to analysis using three baseline classifiers. The primary objective was to investigate whether machine translation exerted any influence on the results of sentiment analysis and to determine the superior performer between Miðeind and Google translations. Our aim was to assess the transferability of sentiment across machine translation processes.\n",
    "\n",
    "## Machine Translations\n",
    "\n",
    "We employed the Google Translator API, which relies on Google's Neural Machine Translation featuring an LSTM architecture. Additionally, we utilized the Miðeind Vélþýðing API for the purpose of machine-translating the reviews. The Miðeind Vélþýðing API is constructed using the multilingual BART model, which was trained using the Fairseq sequence modeling toolkit within the PyTorch framework.\n",
    "\n",
    "### Google Translate\n",
    "\n",
    "All the reviews were effectively translated using the API, and the only preprocessing step performed on the raw data was the removal of \\<br\\/\\>. The absence of errors during the translation process could be attributed to the API's maturity and extensive user adoption. Nevertheless, it's worth noting that the quality of Icelandic language reviews occasionally exhibited idiosyncrasies.\n",
    "\n",
    "### Miðeind\n",
    "\n",
    "The Miðeind Translator encountered challenges when translating the English corpus into Icelandic. To prepare the text for translation, several preprocessing steps were necessary. These steps included consolidating consecutive punctuation marks, eliminating all HTML tags, ensuring there was a whitespace character following punctuation marks, and removing asterisks. Subsequently, we divided the reviews into segments of 128 tokens, which were then processed in batches by the Miðeind translator.\n",
    "\n",
    "## Pre-Processing and feature extraction\n",
    "\n",
    "The original English dataset we lowercased, tokenized and lemmatized and removed stop words, the same was applied on the Icelandic machine translated corpus as well, in addition we also added a prefix _NEG to the words in Icelandic if the term was deemed negative to assist the vectorizer in locating negative remarks.\n",
    "\n",
    "Three baseline classifier pipelines were created that serve as a baseline metric for our scoring for English and machine translated Google and Miðeind datasets, all classifiers use TF-IDF vectorizer, which measure the frequency of a term in each document. It measure how important the term is across all documents. We see scoring of these terms in (#logistic)\n",
    "\n",
    "![](machine_learning.png)\n",
    "\n",
    "# Baseline Classifier Evaluation\n",
    "\n",
    "We utilized the classifiers available in the Scikit-learn Python package for implementing our machine learning models. These models were trained with their default parameters, and hyperparameter tuning was not conducted. It is important to note that superior results can be attained by fine-tuning the hyperparameters.\n",
    "\n",
    "When assessing the statistical measures to gauge the model's performance, we applied equations 1, 2, 3, and 4.\n",
    "\n",
    "\\begin{align}\n",
    "&Accuracy = \\frac{TP+FN}{TP+FP+TN+FN}\n",
    "\\\\\n",
    "&Recall = \\frac{TP}{TP+FN}\n",
    "\\\\\n",
    "&Precision = \\frac{TP}{TP+FP}\n",
    "\\\\\n",
    "&F1 Score = \\frac{2(Recall*Precision)}{Recall+Precision}\n",
    "\\end{align}\n",
    "\n",
    "True Positive (TP) refers to correctly identified positive sentiments, while False Positive (FP) signifies incorrectly identified positive sentiments. True Negative (TN) denotes correctly identified negative sentiments, and False Negative (FN) represents incorrectly identified negative sentiments.\n",
    "\n",
    "The data was divided into training and test sets, with 67% (33,500 reviews) allocated for training the models and 33% (16,500 reviews) reserved for testing the model's performance.\n",
    "\n",
    "![](English_Classification_Report.png)\n",
    "\n",
    "![](Icelandic_Google_Classification_Report.png)\n",
    "\n",
    "![](Icelandic_Miðeind_Classification_Report.png)\n",
    "\n",
    "In this visual representation of the classification report encompassing all classifiers, we observe that Support Vector Classification (SVC) outperformed other models when applied to the data. All models were trained with 33,500 reviews and tested with 16,500. If we establish SVC as our baseline comparative model and employing a weighted F1 score as our evaluation metric, we can discern the following results across different datasets: In the English dataset, the F1 score reached 89.67%, the translated Miðeind dataset achieved an F1 score of 88.36%, and the Google dataset attained an F1 score of 89.33%. These figures suggest that sentiment analysis can carry across Machine Translation when utilizing state-of-the-art machine translation APIs. The loss in accuracy during translation is minimal, with only a 1.31% and 0.34% drop in accuracy, favoring Google's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cae3152",
   "metadata": {},
   "source": [
    "## Support Vector Classifier\n",
    "\n",
    "The SVC (Support Vector Classifier) was the best machine learning algorithm in classifying sentiment, it is a linear binary classification algorithm, were the result is defined as zero or one in binary models. \n",
    "\n",
    "| English Sentiment     | Precision | Recall | F1-Score |\n",
    "|-----------------------|-----------|--------|----------|\n",
    "| negative              |  0.90     | 0.89   | 0.90     |\n",
    "| positive              |  0.89     | 0.91   | 0.90     |\n",
    "\n",
    "| Google Sentiment  | Precision | Recall | F1-Score |\n",
    "|-----------------------|-----------|--------|----------|\n",
    "| negative              |  0.90   | 0.88 | 0.89   |\n",
    "| positive              |  0.89   | 0.90 | 0.89   |\n",
    "\n",
    "| Miðeind Sentiment  | Precision | Recall | F1-Score |\n",
    "|-----------------------|-----------|--------|----------|\n",
    "| negative              |  0.89   | 0.88 | 0.88   |\n",
    "| positive              |  0.88   | 0.89 | 0.89   |\n",
    "\n",
    "When we trained the class it gives us a list of coefficients that represent the relationship between the input variables and the output variable in the model. The coefficient can be interpreted as the relative importance of the word it's classified to, in this case negative or positive. In this chart we can see the top 10 negative and positive values, for a sentence to be positive in this case, it has to have a value of one.\n",
    "\n",
    "![SVC Score](SVC_English_Important.png)\n",
    "\n",
    "![SVC Score](SVC_Google_Important.png)\n",
    "\n",
    "![SVC Score](SVC_Miðeind_Important.png)\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "Logistic Regression is a binary classification algorithm, were the result is defined as zero or one in binary models. \n",
    "\n",
    "\n",
    "| English Sentiment     | Precision | Recall | F1-Score |\n",
    "|-----------------------|-----------|--------|----------|\n",
    "| negative              |  0.90   | 0.88 | 0.89   |\n",
    "| positive              |  0.89   | 0.91 | 0.90   |\n",
    "\n",
    "| Google Sentiment     | Precision | Recall | F1-Score |\n",
    "|-----------------------|-----------|--------|----------|\n",
    "| negative              |  0.90   | 0.88 | 0.89   |\n",
    "| positive              |  0.88   | 0.90 | 0.89   |\n",
    "\n",
    "| Miðeind Sentiment     | Precision | Recall | F1-Score |\n",
    "|-----------------------|-----------|--------|----------|\n",
    "| negative              |  0.88   | 0.87 | 0.88   |\n",
    "| positive              |  0.87   | 0.89 | 0.88   |\n",
    "\n",
    "\n",
    "When we trained the class it gives us a list of coefficients that represent the relationship between the input variables and the output variable in the model. The coefficient can be interpreted as the relative importance of the word it's classified to, in this case negative or positive. In this chart we can see the top 10 negative and positive values, for a sentence to be positive in this case, it has to have a value of one.\n",
    "\n",
    "![LR Score](LR_English_Important.png)\n",
    "\n",
    "![LR Score](LR_Google_Important.png)\n",
    "\n",
    "![LR Score](LR_Miðeind_Important.png)\n",
    "\n",
    "## Naive Bayes\n",
    "\n",
    "Naive Bayes is a classifier for multinomial models, although we employed it for binary classification\n",
    "\n",
    "| English Sentiment     | Precision | Recall | F1-Score |\n",
    "|-----------------------|-----------|--------|----------|\n",
    "| negative              |  0.85   | 0.87 | 0.86   |\n",
    "| positive              |  0.87   | 0.84 | 0.86   |\n",
    "\n",
    "| Google Sentiment     | Precision | Recall | F1-Score |\n",
    "|-----------------------|-----------|--------|----------|\n",
    "| negative              |  0.85   | 0.88 | 0.86   |\n",
    "| positive              |  0.88   | 0.85 | 0.86   |\n",
    "\n",
    "| Miðeind Sentiment     | Precision | Recall | F1-Score |\n",
    "|-----------------------|-----------|--------|----------|\n",
    "| negative              |  0.84   | 0.87 | 0.86   |\n",
    "| positive              |  0.87   | 0.84 | 0.85   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e466f8fc",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46278d9e",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "Next steps are using classifiers that have scalabe sentiment and start looking into deep learning models such as BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99917afa",
   "metadata": {},
   "source": [
    "# Burndown Chart\n",
    "\n",
    "Given the research-oriented nature of our project, as opposed to corporate work, we opted for a Kanban approach rather than Scrum. We started well in advance, with initial preparations and research activities commencing in late July to early August. This timeframe allowed us to familiarize ourselves with the intricacies of machine learning, particularly since only one team member possessed prior experience in Machine Learning and Deep Learning.\n",
    "\n",
    "We've allocated a collective 40 hours per week for all team members, distributed across a span of 20 weeks, aiming to complete this project within this timeframe. This amounts to a total of 800 hours dedicated to the project. We expect the burndown to go under the planned line in October since we are picking up the pace but still keeping the 40 hours as a median.\n",
    "\n",
    "The sum of the spent hours for each team member is\n",
    "- Ólafur Aron Jóhannsson (100)\n",
    "- Eysteinn Örn (44)\n",
    "- Birkir (50)\n",
    "\n",
    "The reason Ólafur Aron has accumulated more hours is due to the fact that he will be departing abroad in late November and returning in early December, during which period his hours will be reduced.\n",
    "\n",
    "![JIRA](jira.png)\n",
    "\n",
    "![Burndown](burndown.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e95052b",
   "metadata": {},
   "source": [
    "# Risk Analysis\n",
    "\n",
    "| Risk                                  | Likelihood (1-5)  | Impact (1-5)  | Responsibility    | Mitigation Strategy |\n",
    "|---------------------------------------|-------------------|---------------|-------------------|---------------------|\n",
    "| Resource Constraints (Time and Computing Power) | 4       | 5             | Eysteinn          | Prioritize key features and models that are critical to the project. Consider using cloud computing resources. |\n",
    "| Training stops/Computer crashes       | 4                 | 4             | Ólafur            | Regular backups and distributed training could mitigate this risk. |\n",
    "| Sprint/Project delay                  | 3                 | 5             | Ólafur            | Address the problem in the standup's and frequent reassessments. |\n",
    "| Incompatibility of Translation APIs   | 3                 | 3             | Birkir            | Have fallback methods for each API, and make the system modular to easily swap out one service for another. |\n",
    "| Classifier Model Inefficiency         | 3                 | 3             | Eysteinn          | Use baseline models for initial testing before using more complex models like BERT, roBERTa, and IceBERT. |\n",
    "| Overfitting in Model Training         | 2                 | 4             | Birkir            | Utilize techniques such as cross-validation and dropout layers. |\n",
    "| Illness in team                       | 2                 | 4             | Whole Team        | Cross-training and comprehensive documentation can help other team members pick up the slack. Tries not getting other team members sick. |\n",
    "| API Rate Limiting or Costs            | 2                 | 3             | Birkir            | Caching translated data and batch processing could help in minimizing the number of API calls. |\n",
    "| A team member quits                   | 1                 | 5             | Whole Team        | Having a documented and modular project architecture allows for easier transition of responsibilities. |\n",
    "| External Dependency Failures (APIs down) | 1              | 2             | Whole Team        | Have a contingency plan, such as a local translation model otherwise wait and focus on a different task |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf97877e",
   "metadata": {},
   "source": [
    "# Meeting Notes\n",
    "\n",
    "In addition to all data gathered we also tried to keep meeting notes as far back as 26. July.\n",
    "\n",
    "![1](1.png)\n",
    "\n",
    "![2](2.png)\n",
    "\n",
    "![3](3.png)\n",
    "\n",
    "![4](4.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
