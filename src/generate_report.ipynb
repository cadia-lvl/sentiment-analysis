{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.0.5) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1111, 2)\n",
      "(209, 2)\n",
      "0     g trúi því varla að maður hafi horft á þetta t...\n",
      "1     etta hefði alveg getað verið Bridgerton þáttur...\n",
      "2     Mjög kjánaleg mynd, eins og við mátti búast  b...\n",
      "3     Mikil vitleysa. Mikið um slapstick og fratboy ...\n",
      "4     Alveg öfugt við það sem að gerði upprunalegu s...\n",
      "                            ...                        \n",
      "95    Svo. Mikið. Ofbeldi. Svakaleg keyrsla. Keanu R...\n",
      "96    Mjög skemmtileg mynd. Ekta Bond  spennandi, fy...\n",
      "97    Nokkuð góð skrímslastórslysamynd. Töluvert öðr...\n",
      "98    Jahá... erfitt að segja  margt einkennilegt vi...\n",
      "99    Mjög skemmtileg mynd. Fyndin. Sniðug saga. Hug...\n",
      "Name: review, Length: 100, dtype: object\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "     ..\n",
      "95    1\n",
      "96    1\n",
      "97    1\n",
      "98    1\n",
      "99    1\n",
      "Name: sentiment, Length: 100, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 21:38:43.624646: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-29 21:38:43.667135: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-29 21:38:44.444958: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/olafurj/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import generate_classification_report as gcr\n",
    "\n",
    "PATH1 = \"\"\n",
    "PATH2 = \"\"\n",
    "\n",
    "d1 = pd.read_csv(PATH1)\n",
    "d2 = pd.read_csv(PATH2)\n",
    "d1.drop([\"num\", \"rating\", \"id\"], axis=1, inplace=True)\n",
    "d2.drop([\"movie\", \"rating\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df_orig = pd.merge(d1, d2, how=\"outer\")\n",
    "\n",
    "device = \"cuda\"\n",
    "model = \"./electra-base-google-batch8-remove-noise-model/\"\n",
    "\n",
    "\n",
    "total = 0\n",
    "for i in range(0, 10):\n",
    "    r = random.randint(0, 10000)\n",
    "\n",
    "    fifty_negative = (\n",
    "        df_orig.where(lambda x: x[\"sentiment\"] == \"Negative\")\n",
    "        .dropna()\n",
    "        .sample(n=50, random_state=r)\n",
    "    )\n",
    "    fifty_positive = (\n",
    "        df_orig.where(lambda x: x[\"sentiment\"] == \"Positive\")\n",
    "        .dropna()\n",
    "        .sample(n=50, random_state=r)\n",
    "    )\n",
    "\n",
    "    new_df = pd.merge(\n",
    "        fifty_negative, fifty_positive, on=[\"sentiment\", \"review\"], how=\"outer\"\n",
    "    )\n",
    "    new_df.sentiment = new_df.sentiment.apply(lambda x: 1 if x == \"Positive\" else 0)\n",
    "    X_all = new_df.review\n",
    "    y_all = new_df.sentiment\n",
    "    accuracy = gcr.call_model(X_all, y_all, model, device, accuracy=True)\n",
    "    total += accuracy\n",
    "    print(\"acc: {0:.4f}, seed: {1}, i: {2}\".format(accuracy, r, i))\n",
    "\n",
    "\n",
    "print(\"Average accuracy: \", total / 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
