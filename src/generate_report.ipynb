{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.0.5) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1111, 2)\n",
      "(209, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 02:56:33.787796: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 02:56:34.038470: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-28 02:56:35.001355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/olafurj/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot switch from automatic field numbering to manual field specification",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5712/2049249083.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acc: {:20.15f}, seed: {1}, i: {2}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot switch from automatic field numbering to manual field specification"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    ")\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "from pprint import pprint\n",
    "import generate_classification_report as gcr\n",
    "#def call_model(X_all, y_all, folder, device):\n",
    "path1 = 'external-icelandic-reviews/data/imdb-split/hannes-reviews-reviews-with-sentiment.csv'\n",
    "path2 = 'external-icelandic-reviews/data/imdb-split/kvikmyndaryni-reviews-with-sentiment.csv'\n",
    "\n",
    "d1 = pd.read_csv(path1)\n",
    "d2 = pd.read_csv(path2)\n",
    "d1.drop(['num', 'rating', 'id'], axis=1, inplace=True)\n",
    "d2.drop(['movie', 'rating'], axis=1, inplace=True)\n",
    "\n",
    "print(d1.shape)\n",
    "print(d2.shape)\n",
    "\n",
    "df_orig = pd.merge(d1, d2, how='outer')\n",
    "\n",
    "#print(df.shape)\n",
    "#print(df.head())\n",
    "#print(df.value_counts())\n",
    "\n",
    "#all_pos1 = d1.where(lambda x: x['sentiment'] =='Positive')\n",
    "device = 'cuda'\n",
    "model = './electra-base-google-batch8-remove-noise-model/'\n",
    "\n",
    "\n",
    "total = 0\n",
    "for i in range(0, 10):\n",
    "    r = random.randint(0, 10000)\n",
    "    \n",
    "    fifty_negative = df_orig.where(lambda x: x['sentiment'] == 'Negative').dropna().sample(n=50, random_state=r)\n",
    "    fifty_positive = df_orig.where(lambda x: x['sentiment'] == 'Positive').dropna().sample(n=50, random_state=r)\n",
    "\n",
    "    new_df = pd.merge(fifty_negative, fifty_positive, on=['sentiment', 'review'], how='outer')\n",
    "    new_df.sentiment = new_df.sentiment.apply(lambda x: 1 if x == 'Positive' else 0)\n",
    "    X_all = new_df.review\n",
    "    y_all = new_df.sentiment\n",
    "    accuracy = gcr.call_model(X_all, y_all, model, device)\n",
    "    total += accuracy\n",
    "    print('acc: {0:.4f}, seed: {1}, i: {2}'.format(accuracy, r, i))\n",
    "\n",
    "    \n",
    "print('Average accuracy: ', total/10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
